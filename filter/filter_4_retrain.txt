LeNet width multiplier : 4
initialization uniform
initialization uniform
==> Loading from lenet_adv_admm.pt
new best adv acc is 92.83
saving model lenet_adv_retrained.pt

Test set: Average nat_loss: 0.1283, nat_Accuracy: 9578/10000 (95.78%)


Test set: Average adv_loss: 0.2122, adv Accuracy: 9283/10000 (92.83%)

inside prepare
['', 'basic_model', 'basic_model.conv1', 'basic_model.conv2', 'basic_model.fc1', 'basic_model.fc2']
<============masking both weights and gradients for retrain
<============testing sparsity before retrain
<===sparsity type is filter
<===layers to be pruned are {'conv1.weight': 0.8, 'conv2.weight': 0.947}
inside if
{'basic_model.conv1.weight': 0.8, 'basic_model.conv2.weight': 0.947}
filter sparsity of layer basic_model.conv1.weight is 0.75
filter sparsity of layer basic_model.conv2.weight is 0.9375
only consider conv layers, compression rate is 13.6

Test set: Average nat_loss: 0.4301, nat_Accuracy: 8544/10000 (85.44%)


Test set: Average adv_loss: 0.6279, adv Accuracy: 7815/10000 (78.15%)

nat_cross_entropy loss: 0.7102789282798767  adv_cross_entropy loss : 0.8956137895584106
Train Epoch: 0 [0/60000 (0%)]	Loss: 0.895614
nat_cross_entropy loss: 0.15438170731067657  adv_cross_entropy loss : 0.23072904348373413
Train Epoch: 0 [32000/60000 (53%)]	Loss: 0.230729

Test set: Average nat_loss: 0.1521, nat_Accuracy: 9498/10000 (94.98%)


Test set: Average adv_loss: 0.2346, adv Accuracy: 9239/10000 (92.39%)

nat_cross_entropy loss: 0.20001758635044098  adv_cross_entropy loss : 0.2603539824485779
Train Epoch: 1 [0/60000 (0%)]	Loss: 0.260354
nat_cross_entropy loss: 0.19494839012622833  adv_cross_entropy loss : 0.26873111724853516
Train Epoch: 1 [32000/60000 (53%)]	Loss: 0.268731

Test set: Average nat_loss: 0.1306, nat_Accuracy: 9574/10000 (95.74%)


Test set: Average adv_loss: 0.2385, adv Accuracy: 9202/10000 (92.02%)

nat_cross_entropy loss: 0.2185807079076767  adv_cross_entropy loss : 0.30702996253967285
Train Epoch: 2 [0/60000 (0%)]	Loss: 0.307030
nat_cross_entropy loss: 0.14488646388053894  adv_cross_entropy loss : 0.21418458223342896
Train Epoch: 2 [32000/60000 (53%)]	Loss: 0.214185
new best adv acc is 93.89
saving model lenet_adv_retrained.pt

Test set: Average nat_loss: 0.1163, nat_Accuracy: 9620/10000 (96.20%)


Test set: Average adv_loss: 0.1872, adv Accuracy: 9389/10000 (93.89%)

nat_cross_entropy loss: 0.24079976975917816  adv_cross_entropy loss : 0.31890469789505005
Train Epoch: 3 [0/60000 (0%)]	Loss: 0.318905
nat_cross_entropy loss: 0.06364939361810684  adv_cross_entropy loss : 0.17708994448184967
Train Epoch: 3 [32000/60000 (53%)]	Loss: 0.177090
new best adv acc is 94.45
saving model lenet_adv_retrained.pt

Test set: Average nat_loss: 0.1069, nat_Accuracy: 9660/10000 (96.60%)


Test set: Average adv_loss: 0.1781, adv Accuracy: 9445/10000 (94.45%)

nat_cross_entropy loss: 0.16818012297153473  adv_cross_entropy loss : 0.2088303565979004
Train Epoch: 4 [0/60000 (0%)]	Loss: 0.208830
nat_cross_entropy loss: 0.09623116254806519  adv_cross_entropy loss : 0.27025407552719116
Train Epoch: 4 [32000/60000 (53%)]	Loss: 0.270254

Test set: Average nat_loss: 0.1169, nat_Accuracy: 9627/10000 (96.27%)


Test set: Average adv_loss: 0.1950, adv Accuracy: 9386/10000 (93.86%)

nat_cross_entropy loss: 0.06924563646316528  adv_cross_entropy loss : 0.13034097850322723
Train Epoch: 5 [0/60000 (0%)]	Loss: 0.130341
nat_cross_entropy loss: 0.0845528319478035  adv_cross_entropy loss : 0.2187609225511551
Train Epoch: 5 [32000/60000 (53%)]	Loss: 0.218761

Test set: Average nat_loss: 0.1140, nat_Accuracy: 9647/10000 (96.47%)


Test set: Average adv_loss: 0.2063, adv Accuracy: 9325/10000 (93.25%)

nat_cross_entropy loss: 0.1202329471707344  adv_cross_entropy loss : 0.23684090375900269
Train Epoch: 6 [0/60000 (0%)]	Loss: 0.236841
nat_cross_entropy loss: 0.05946774780750275  adv_cross_entropy loss : 0.08575703948736191
Train Epoch: 6 [32000/60000 (53%)]	Loss: 0.085757
new best adv acc is 94.73
saving model lenet_adv_retrained.pt

Test set: Average nat_loss: 0.1036, nat_Accuracy: 9659/10000 (96.59%)


Test set: Average adv_loss: 0.1646, adv Accuracy: 9473/10000 (94.73%)

nat_cross_entropy loss: 0.13537855446338654  adv_cross_entropy loss : 0.20108254253864288
Train Epoch: 7 [0/60000 (0%)]	Loss: 0.201083
nat_cross_entropy loss: 0.006941830739378929  adv_cross_entropy loss : 0.02167833410203457
Train Epoch: 7 [32000/60000 (53%)]	Loss: 0.021678

Test set: Average nat_loss: 0.1085, nat_Accuracy: 9672/10000 (96.72%)


Test set: Average adv_loss: 0.1872, adv Accuracy: 9406/10000 (94.06%)

nat_cross_entropy loss: 0.039870839565992355  adv_cross_entropy loss : 0.08258223533630371
Train Epoch: 8 [0/60000 (0%)]	Loss: 0.082582
nat_cross_entropy loss: 0.08710389584302902  adv_cross_entropy loss : 0.16698889434337616
Train Epoch: 8 [32000/60000 (53%)]	Loss: 0.166989

Test set: Average nat_loss: 0.1171, nat_Accuracy: 9640/10000 (96.40%)


Test set: Average adv_loss: 0.1852, adv Accuracy: 9417/10000 (94.17%)

nat_cross_entropy loss: 0.1371358186006546  adv_cross_entropy loss : 0.215982124209404
Train Epoch: 9 [0/60000 (0%)]	Loss: 0.215982
nat_cross_entropy loss: 0.10848668962717056  adv_cross_entropy loss : 0.22106564044952393
Train Epoch: 9 [32000/60000 (53%)]	Loss: 0.221066

Test set: Average nat_loss: 0.1104, nat_Accuracy: 9671/10000 (96.71%)


Test set: Average adv_loss: 0.2135, adv Accuracy: 9376/10000 (93.76%)

nat_cross_entropy loss: 0.1369798630475998  adv_cross_entropy loss : 0.49023205041885376
Train Epoch: 10 [0/60000 (0%)]	Loss: 0.490232
nat_cross_entropy loss: 0.11075117439031601  adv_cross_entropy loss : 0.13986121118068695
Train Epoch: 10 [32000/60000 (53%)]	Loss: 0.139861
new best adv acc is 94.9
saving model lenet_adv_retrained.pt

Test set: Average nat_loss: 0.0982, nat_Accuracy: 9678/10000 (96.78%)


Test set: Average adv_loss: 0.1652, adv Accuracy: 9490/10000 (94.90%)

nat_cross_entropy loss: 0.06325523555278778  adv_cross_entropy loss : 0.13196444511413574
Train Epoch: 11 [0/60000 (0%)]	Loss: 0.131964
nat_cross_entropy loss: 0.01739622838795185  adv_cross_entropy loss : 0.07824623584747314
Train Epoch: 11 [32000/60000 (53%)]	Loss: 0.078246

Test set: Average nat_loss: 0.1064, nat_Accuracy: 9679/10000 (96.79%)


Test set: Average adv_loss: 0.1912, adv Accuracy: 9424/10000 (94.24%)

nat_cross_entropy loss: 0.18028897047042847  adv_cross_entropy loss : 0.26570025086402893
Train Epoch: 12 [0/60000 (0%)]	Loss: 0.265700
nat_cross_entropy loss: 0.029597580432891846  adv_cross_entropy loss : 0.08982981741428375
Train Epoch: 12 [32000/60000 (53%)]	Loss: 0.089830
new best adv acc is 95.03
saving model lenet_adv_retrained.pt

Test set: Average nat_loss: 0.0971, nat_Accuracy: 9691/10000 (96.91%)


Test set: Average adv_loss: 0.1626, adv Accuracy: 9503/10000 (95.03%)

nat_cross_entropy loss: 0.10106805711984634  adv_cross_entropy loss : 0.13862095773220062
Train Epoch: 13 [0/60000 (0%)]	Loss: 0.138621
nat_cross_entropy loss: 0.014017368666827679  adv_cross_entropy loss : 0.0503673292696476
Train Epoch: 13 [32000/60000 (53%)]	Loss: 0.050367

Test set: Average nat_loss: 0.0922, nat_Accuracy: 9712/10000 (97.12%)


Test set: Average adv_loss: 0.1785, adv Accuracy: 9469/10000 (94.69%)

nat_cross_entropy loss: 0.24187108874320984  adv_cross_entropy loss : 0.28229591250419617
Train Epoch: 14 [0/60000 (0%)]	Loss: 0.282296
nat_cross_entropy loss: 0.259757936000824  adv_cross_entropy loss : 0.3362307548522949
Train Epoch: 14 [32000/60000 (53%)]	Loss: 0.336231

Test set: Average nat_loss: 0.1117, nat_Accuracy: 9648/10000 (96.48%)


Test set: Average adv_loss: 0.1883, adv Accuracy: 9406/10000 (94.06%)

nat_cross_entropy loss: 0.0333164744079113  adv_cross_entropy loss : 0.08725851029157639
Train Epoch: 15 [0/60000 (0%)]	Loss: 0.087259
nat_cross_entropy loss: 0.08753738552331924  adv_cross_entropy loss : 0.21819619834423065
Train Epoch: 15 [32000/60000 (53%)]	Loss: 0.218196

Test set: Average nat_loss: 0.1026, nat_Accuracy: 9668/10000 (96.68%)


Test set: Average adv_loss: 0.1797, adv Accuracy: 9449/10000 (94.49%)

nat_cross_entropy loss: 0.06001819670200348  adv_cross_entropy loss : 0.10689416527748108
Train Epoch: 16 [0/60000 (0%)]	Loss: 0.106894
nat_cross_entropy loss: 0.10343518853187561  adv_cross_entropy loss : 0.21158525347709656
Train Epoch: 16 [32000/60000 (53%)]	Loss: 0.211585

Test set: Average nat_loss: 0.1007, nat_Accuracy: 9690/10000 (96.90%)


Test set: Average adv_loss: 0.1663, adv Accuracy: 9479/10000 (94.79%)

nat_cross_entropy loss: 0.06247205659747124  adv_cross_entropy loss : 0.12688584625720978
Train Epoch: 17 [0/60000 (0%)]	Loss: 0.126886
nat_cross_entropy loss: 0.25205686688423157  adv_cross_entropy loss : 0.40665027499198914
Train Epoch: 17 [32000/60000 (53%)]	Loss: 0.406650

Test set: Average nat_loss: 0.1124, nat_Accuracy: 9642/10000 (96.42%)


Test set: Average adv_loss: 0.1935, adv Accuracy: 9391/10000 (93.91%)

nat_cross_entropy loss: 0.02959413081407547  adv_cross_entropy loss : 0.041610974818468094
Train Epoch: 18 [0/60000 (0%)]	Loss: 0.041611
nat_cross_entropy loss: 0.1067039966583252  adv_cross_entropy loss : 0.14812368154525757
Train Epoch: 18 [32000/60000 (53%)]	Loss: 0.148124

Test set: Average nat_loss: 0.0947, nat_Accuracy: 9709/10000 (97.09%)


Test set: Average adv_loss: 0.1724, adv Accuracy: 9468/10000 (94.68%)

nat_cross_entropy loss: 0.06715612858533859  adv_cross_entropy loss : 0.14559580385684967
Train Epoch: 19 [0/60000 (0%)]	Loss: 0.145596
nat_cross_entropy loss: 0.003571459325030446  adv_cross_entropy loss : 0.019383946433663368
Train Epoch: 19 [32000/60000 (53%)]	Loss: 0.019384

Test set: Average nat_loss: 0.0913, nat_Accuracy: 9731/10000 (97.31%)


Test set: Average adv_loss: 0.1748, adv Accuracy: 9460/10000 (94.60%)

nat_cross_entropy loss: 0.01613028161227703  adv_cross_entropy loss : 0.06800849735736847
Train Epoch: 20 [0/60000 (0%)]	Loss: 0.068008
nat_cross_entropy loss: 0.15465152263641357  adv_cross_entropy loss : 0.22450019419193268
Train Epoch: 20 [32000/60000 (53%)]	Loss: 0.224500

Test set: Average nat_loss: 0.1121, nat_Accuracy: 9655/10000 (96.55%)


Test set: Average adv_loss: 0.1971, adv Accuracy: 9399/10000 (93.99%)

nat_cross_entropy loss: 0.052978966385126114  adv_cross_entropy loss : 0.11100786924362183
Train Epoch: 21 [0/60000 (0%)]	Loss: 0.111008
nat_cross_entropy loss: 0.0767352432012558  adv_cross_entropy loss : 0.2245040386915207
Train Epoch: 21 [32000/60000 (53%)]	Loss: 0.224504

Test set: Average nat_loss: 0.1070, nat_Accuracy: 9668/10000 (96.68%)


Test set: Average adv_loss: 0.1765, adv Accuracy: 9448/10000 (94.48%)

nat_cross_entropy loss: 0.08729522675275803  adv_cross_entropy loss : 0.15243805944919586
Train Epoch: 22 [0/60000 (0%)]	Loss: 0.152438
nat_cross_entropy loss: 0.10852397233247757  adv_cross_entropy loss : 0.209260031580925
Train Epoch: 22 [32000/60000 (53%)]	Loss: 0.209260

Test set: Average nat_loss: 0.1110, nat_Accuracy: 9638/10000 (96.38%)


Test set: Average adv_loss: 0.1897, adv Accuracy: 9399/10000 (93.99%)

nat_cross_entropy loss: 0.0617535375058651  adv_cross_entropy loss : 0.17310982942581177
Train Epoch: 23 [0/60000 (0%)]	Loss: 0.173110
nat_cross_entropy loss: 0.005858835764229298  adv_cross_entropy loss : 0.02879386954009533
Train Epoch: 23 [32000/60000 (53%)]	Loss: 0.028794

Test set: Average nat_loss: 0.1086, nat_Accuracy: 9655/10000 (96.55%)


Test set: Average adv_loss: 0.1970, adv Accuracy: 9379/10000 (93.79%)

nat_cross_entropy loss: 0.009700361639261246  adv_cross_entropy loss : 0.043363165110349655
Train Epoch: 24 [0/60000 (0%)]	Loss: 0.043363
nat_cross_entropy loss: 0.16917778551578522  adv_cross_entropy loss : 0.22424902021884918
Train Epoch: 24 [32000/60000 (53%)]	Loss: 0.224249

Test set: Average nat_loss: 0.1138, nat_Accuracy: 9650/10000 (96.50%)


Test set: Average adv_loss: 0.1908, adv Accuracy: 9420/10000 (94.20%)

nat_cross_entropy loss: 0.13658808171749115  adv_cross_entropy loss : 0.15726228058338165
Train Epoch: 25 [0/60000 (0%)]	Loss: 0.157262
nat_cross_entropy loss: 0.11507516354322433  adv_cross_entropy loss : 0.2613809108734131
Train Epoch: 25 [32000/60000 (53%)]	Loss: 0.261381

Test set: Average nat_loss: 0.1013, nat_Accuracy: 9689/10000 (96.89%)


Test set: Average adv_loss: 0.1779, adv Accuracy: 9454/10000 (94.54%)

nat_cross_entropy loss: 0.012969882227480412  adv_cross_entropy loss : 0.04190310090780258
Train Epoch: 26 [0/60000 (0%)]	Loss: 0.041903
nat_cross_entropy loss: 0.02828768454492092  adv_cross_entropy loss : 0.08320722728967667
Train Epoch: 26 [32000/60000 (53%)]	Loss: 0.083207

Test set: Average nat_loss: 0.0981, nat_Accuracy: 9688/10000 (96.88%)


Test set: Average adv_loss: 0.1760, adv Accuracy: 9443/10000 (94.43%)

nat_cross_entropy loss: 0.2296789288520813  adv_cross_entropy loss : 0.2963433265686035
Train Epoch: 27 [0/60000 (0%)]	Loss: 0.296343
nat_cross_entropy loss: 0.03755149617791176  adv_cross_entropy loss : 0.10194925963878632
Train Epoch: 27 [32000/60000 (53%)]	Loss: 0.101949

Test set: Average nat_loss: 0.0991, nat_Accuracy: 9687/10000 (96.87%)


Test set: Average adv_loss: 0.1840, adv Accuracy: 9425/10000 (94.25%)

nat_cross_entropy loss: 0.023271063342690468  adv_cross_entropy loss : 0.06563405692577362
Train Epoch: 28 [0/60000 (0%)]	Loss: 0.065634
nat_cross_entropy loss: 0.015969863161444664  adv_cross_entropy loss : 0.08443611115217209
Train Epoch: 28 [32000/60000 (53%)]	Loss: 0.084436

Test set: Average nat_loss: 0.1209, nat_Accuracy: 9629/10000 (96.29%)


Test set: Average adv_loss: 0.2063, adv Accuracy: 9404/10000 (94.04%)

nat_cross_entropy loss: 0.07042668014764786  adv_cross_entropy loss : 0.14566636085510254
Train Epoch: 29 [0/60000 (0%)]	Loss: 0.145666
nat_cross_entropy loss: 0.06919659674167633  adv_cross_entropy loss : 0.1809951663017273
Train Epoch: 29 [32000/60000 (53%)]	Loss: 0.180995

Test set: Average nat_loss: 0.1056, nat_Accuracy: 9669/10000 (96.69%)


Test set: Average adv_loss: 0.1759, adv Accuracy: 9455/10000 (94.55%)

nat_cross_entropy loss: 0.06484083831310272  adv_cross_entropy loss : 0.07514176517724991
Train Epoch: 30 [0/60000 (0%)]	Loss: 0.075142
nat_cross_entropy loss: 0.030118538066744804  adv_cross_entropy loss : 0.11161594837903976
Train Epoch: 30 [32000/60000 (53%)]	Loss: 0.111616

Test set: Average nat_loss: 0.1001, nat_Accuracy: 9695/10000 (96.95%)


Test set: Average adv_loss: 0.1660, adv Accuracy: 9487/10000 (94.87%)

nat_cross_entropy loss: 0.11680752038955688  adv_cross_entropy loss : 0.17470350861549377
Train Epoch: 31 [0/60000 (0%)]	Loss: 0.174704
nat_cross_entropy loss: 0.08255507797002792  adv_cross_entropy loss : 0.16360875964164734
Train Epoch: 31 [32000/60000 (53%)]	Loss: 0.163609

Test set: Average nat_loss: 0.1059, nat_Accuracy: 9682/10000 (96.82%)


Test set: Average adv_loss: 0.1848, adv Accuracy: 9423/10000 (94.23%)

nat_cross_entropy loss: 0.027309322729706764  adv_cross_entropy loss : 0.11449754983186722
Train Epoch: 32 [0/60000 (0%)]	Loss: 0.114498
nat_cross_entropy loss: 0.09735909849405289  adv_cross_entropy loss : 0.11783496290445328
Train Epoch: 32 [32000/60000 (53%)]	Loss: 0.117835
new best adv acc is 95.06
saving model lenet_adv_retrained.pt

Test set: Average nat_loss: 0.0948, nat_Accuracy: 9727/10000 (97.27%)


Test set: Average adv_loss: 0.1691, adv Accuracy: 9506/10000 (95.06%)

nat_cross_entropy loss: 0.06020760536193848  adv_cross_entropy loss : 0.11523105204105377
Train Epoch: 33 [0/60000 (0%)]	Loss: 0.115231
nat_cross_entropy loss: 0.03768891096115112  adv_cross_entropy loss : 0.11165277659893036
Train Epoch: 33 [32000/60000 (53%)]	Loss: 0.111653

Test set: Average nat_loss: 0.1109, nat_Accuracy: 9661/10000 (96.61%)


Test set: Average adv_loss: 0.2137, adv Accuracy: 9358/10000 (93.58%)

nat_cross_entropy loss: 0.026274951174855232  adv_cross_entropy loss : 0.15744012594223022
Train Epoch: 34 [0/60000 (0%)]	Loss: 0.157440
nat_cross_entropy loss: 0.036480747163295746  adv_cross_entropy loss : 0.08400766551494598
Train Epoch: 34 [32000/60000 (53%)]	Loss: 0.084008

Test set: Average nat_loss: 0.1122, nat_Accuracy: 9675/10000 (96.75%)


Test set: Average adv_loss: 0.1955, adv Accuracy: 9414/10000 (94.14%)

nat_cross_entropy loss: 0.05267566069960594  adv_cross_entropy loss : 0.13466821610927582
Train Epoch: 35 [0/60000 (0%)]	Loss: 0.134668
nat_cross_entropy loss: 0.12423212081193924  adv_cross_entropy loss : 0.26553478837013245
Train Epoch: 35 [32000/60000 (53%)]	Loss: 0.265535

Test set: Average nat_loss: 0.1235, nat_Accuracy: 9632/10000 (96.32%)


Test set: Average adv_loss: 0.2091, adv Accuracy: 9387/10000 (93.87%)

nat_cross_entropy loss: 0.24062390625476837  adv_cross_entropy loss : 0.28321582078933716
Train Epoch: 36 [0/60000 (0%)]	Loss: 0.283216
nat_cross_entropy loss: 0.03673091530799866  adv_cross_entropy loss : 0.12426154315471649
Train Epoch: 36 [32000/60000 (53%)]	Loss: 0.124262

Test set: Average nat_loss: 0.1058, nat_Accuracy: 9689/10000 (96.89%)


Test set: Average adv_loss: 0.1831, adv Accuracy: 9436/10000 (94.36%)

nat_cross_entropy loss: 0.07015834748744965  adv_cross_entropy loss : 0.12392397969961166
Train Epoch: 37 [0/60000 (0%)]	Loss: 0.123924
nat_cross_entropy loss: 0.015891801565885544  adv_cross_entropy loss : 0.04303388297557831
Train Epoch: 37 [32000/60000 (53%)]	Loss: 0.043034

Test set: Average nat_loss: 0.0997, nat_Accuracy: 9700/10000 (97.00%)


Test set: Average adv_loss: 0.1795, adv Accuracy: 9433/10000 (94.33%)

nat_cross_entropy loss: 0.06843876093626022  adv_cross_entropy loss : 0.13287514448165894
Train Epoch: 38 [0/60000 (0%)]	Loss: 0.132875
nat_cross_entropy loss: 0.03424142673611641  adv_cross_entropy loss : 0.09592840075492859
Train Epoch: 38 [32000/60000 (53%)]	Loss: 0.095928

Test set: Average nat_loss: 0.0954, nat_Accuracy: 9722/10000 (97.22%)


Test set: Average adv_loss: 0.1811, adv Accuracy: 9476/10000 (94.76%)

nat_cross_entropy loss: 0.0885053277015686  adv_cross_entropy loss : 0.15559019148349762
Train Epoch: 39 [0/60000 (0%)]	Loss: 0.155590
nat_cross_entropy loss: 0.03331387788057327  adv_cross_entropy loss : 0.08796144276857376
Train Epoch: 39 [32000/60000 (53%)]	Loss: 0.087961

Test set: Average nat_loss: 0.0990, nat_Accuracy: 9696/10000 (96.96%)


Test set: Average adv_loss: 0.1726, adv Accuracy: 9454/10000 (94.54%)

nat_cross_entropy loss: 0.017941365018486977  adv_cross_entropy loss : 0.06572488695383072
Train Epoch: 40 [0/60000 (0%)]	Loss: 0.065725
nat_cross_entropy loss: 0.047987859696149826  adv_cross_entropy loss : 0.09808893501758575
Train Epoch: 40 [32000/60000 (53%)]	Loss: 0.098089

Test set: Average nat_loss: 0.1014, nat_Accuracy: 9704/10000 (97.04%)


Test set: Average adv_loss: 0.1694, adv Accuracy: 9503/10000 (95.03%)

<===sparsity type is filter
<===layers to be pruned are {'conv1.weight': 0.8, 'conv2.weight': 0.947}
inside if
{'basic_model.conv1.weight': 0.8, 'basic_model.conv2.weight': 0.947}
filter sparsity of layer basic_model.conv1.weight is 0.75
filter sparsity of layer basic_model.conv2.weight is 0.9375
only consider conv layers, compression rate is 13.6

Test set: Average nat_loss: 0.1014, nat_Accuracy: 9704/10000 (97.04%)


Test set: Average adv_loss: 0.1680, adv Accuracy: 9488/10000 (94.88%)

